{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of HybridDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HybridDict` is a dictionary-based class. It can store matrices or tensors in either memory (by numpy) or disk (by HDF5). Since it can provide a unified way to handle arrays in both memory and disk (thanks to the similar way of indexing of numpy and h5py), it is called a **dictionary that hybrids both memory and disk arrays**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyscf.dh.util import HybridDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, we see how `HybridDict` stores a numpy array, as well as allocate zero-initialized (5, 5) double-type variable space in disk by h5py (HDF5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numpy_array': array([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]]),\n",
       " 'hdf5_array': <HDF5 dataset \"hdf5_array\": shape (5, 5), type \"<f8\">}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors = HybridDict()\n",
    "tensors[\"numpy_array\"] = np.eye(5)\n",
    "tensors.create(\"hdf5_array\", shape=(5, 5), incore=False)\n",
    "tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code modifies the HDF5 data. To retrive the whole array in disk, use `[:]` or `[()]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.11059277, -0.61265821,  1.02197176, -0.19033687,  0.28984891],\n",
       "       [ 1.65725868, -0.05450106,  0.22574605, -0.13893546,  0.64403076],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[\"hdf5_array\"][1:3] = np.random.randn(2, 5)\n",
    "tensors[\"hdf5_array\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify HDF5 data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HDF5 array in `HybridDict`, by default,\n",
    "\n",
    "- file location is PySCF's temporary directory (defined by `pyscf.lib.param.TMPDIR`) if PySCF is detected, or `/tmp` is there's no PySCF installed.\n",
    "- file name is given by python's tempfile utility; after instance of `HybridDict` destroyed, the temporary HDF5 file will also be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overide default settings, when creating instance of `HybridDict`,\n",
    "\n",
    "- `pathdir` changes file location (directory);\n",
    "- `chkfile_name` changes file name.\n",
    "\n",
    "It should be noted that the file must be exist before instantiation. `HybridDict` does not create a new file for HDF5 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code begins with `!` is executed in bash, not python\n",
    "! touch temporary_hdf5_data.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = HybridDict(chkfile_name=\"temporary_hdf5_data.h5\", pathdir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 a a 96 Sep  6 22:00 temporary_hdf5_data.h5\n"
     ]
    }
   ],
   "source": [
    "! ls -al temporary_hdf5_data.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may see that disk space is increased when some data writed into disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"hdf5_array\": shape (20, 20), type \"<f8\">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors.create(\"hdf5_array\", data=np.random.randn(20, 20), incore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 a a 5248 Sep  6 22:00 temporary_hdf5_data.h5\n"
     ]
    }
   ],
   "source": [
    "! ls -al temporary_hdf5_data.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we create this `temporary_hdf5_data.h5` file in a conventional way, this file may not be destroyed when `tensors` (as instance of `HybridDict`) finishes its lifecycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options for creating an array.\n",
    "\n",
    "To control whether array is created in memory or disk, use option `incore=` in member function `HybridDict.create`. True for memory (numpy), while False for disk (HDF5). Usage of this option is shown in [Basic Usage](#basic-usage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a valid data entry, there can be three ways:\n",
    "\n",
    "1. Use `HybridDict` as an ordinary dictionary:\n",
    "\n",
    "    ```python\n",
    "    tensors[\"array\"] = some_array_in_memory\n",
    "    ```\n",
    "    \n",
    "    ```{Note}\n",
    "    Note that `HybridDict` class should be only used as array data manager.\n",
    "    It is not recommended to save values other than numpy array or HDF5 data in this class.\n",
    "    More specifically, types such as list, tuple, dictionary, simple types are not recommended\n",
    "    to be stored in this class.\n",
    "    \n",
    "    It is strongly not recommended to save values that is not serializable.\n",
    "    If do so, member function `HybridDict.dump` can be affected.\n",
    "    ```\n",
    "\n",
    "2. If array is in memory, using member function `HybridDict.create` with `data=` option; this is virtually the same to the first way, but could also store some data in disk:\n",
    "\n",
    "    ```python\n",
    "    # the same to first way\n",
    "    tensors.create(\"array\", data=some_array_in_memory)\n",
    "    # store array to disk\n",
    "    tensors.create(\"array\", data=some_array_in_memory, incore=False)\n",
    "    # additionally cast type\n",
    "    tensors.create(\"array\", data=some_array_in_memory, dtype=complex)\n",
    "    ```\n",
    "\n",
    "3. If some array is not available in memory, then create an zero-initialized array on disk by calling member function `HybridDict.create` with `shape=` and `incore=False` option:\n",
    "\n",
    "    ```python\n",
    "    # create (1000, 1000) array on disk\n",
    "    tensors.create(\"array\", shape=(1000, 1000), incore=False)\n",
    "    ```\n",
    "    \n",
    "    Then write data by batch that is available in memory:\n",
    "    \n",
    "    ```python\n",
    "    # suppose that array size (10, 1000) is acceptable in memory\n",
    "    for i in range(100):\n",
    "        tensors[\"array\"][10*i:10*(i+1)] = some_batched_array_in_memory\n",
    "    ```\n",
    "    \n",
    "It should be noted that options `data=` and `shape=` are incompatible (one should not declare data shape for new data, while data itself is actually available). So programmer should not use these options simultanously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump and load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HybridDict` class provides dump and load utility. Since this class handles disk-based and memory-based data differently, those data are dumped to two different files. HDF5 file is copied as is, while numpy arrays and other entries are stored by pickle package. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that have both \n",
    "tensors = HybridDict()\n",
    "tensors.create(\"numpy_array_dumped\", data=np.random.randn(5, 5))\n",
    "tensors.create(\"hdf5_array_dumped\", data=np.random.randn(5, 5), incore=False)\n",
    "# dump to `dumped.h5` and `dumped.dat`\n",
    "tensors.dump(h5_path=\"dumped.h5\", dat_path=\"dumped.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load these files to construct a new `HybridDict` instance. Additional parameter options are passed into consturctor of `HybridDict`. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! touch disk_of_tensors_loaded.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hdf5_array_dumped': <HDF5 dataset \"hdf5_array_dumped\": shape (5, 5), type \"<f8\">,\n",
       " 'numpy_array_dumped': array([[ 0.60168714,  1.38361886,  0.8212771 , -1.20283382, -0.06599009],\n",
       "        [-0.34737881, -0.36756216,  1.90771333,  1.48354733,  0.10901779],\n",
       "        [ 0.87932125,  1.33943419, -0.51066958,  0.20387545,  0.61703993],\n",
       "        [ 0.55893424,  0.84483485,  0.3450849 ,  0.33837149,  1.23697113],\n",
       "        [ 0.14952038, -0.43165432, -0.59371613,  0.76986518, -0.7204273 ]]),\n",
       " 'hdf5_array_appended': <HDF5 dataset \"hdf5_array_appended\": shape (10, 10), type \"<f8\">}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors_loaded = HybridDict.pick(\n",
    "    # load data from previous instance\n",
    "    h5_path=\"dumped.h5\", dat_path=\"dumped.dat\",\n",
    "    # specify HDF5 file location for current instance\n",
    "    pathdir=\".\", chkfile_name=\"disk_of_tensors_loaded.h5\")\n",
    "\n",
    "tensors_loaded.create(\"hdf5_array_appended\", data=np.random.randn(10, 10), incore=False)\n",
    "tensors_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Note}\n",
    "\n",
    "Note that loaded HDF5 file will not be modified.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 a a 5096 Sep  6 22:00 disk_of_tensors_loaded.h5\n",
      "-rw------- 1 a a 2248 Sep  6 22:00 dumped.h5\n"
     ]
    }
   ],
   "source": [
    "! ls -al dumped.h5 disk_of_tensors_loaded.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# clean scratch files in this document\n",
    "! rm *.h5\n",
    "! rm *.dat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
